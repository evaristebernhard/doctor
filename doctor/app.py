
"""
é¡¹ç›®å…¥å£æ–‡ä»¶ï¼Œæ„å»ºGradioç•Œé¢ï¼Œå¤„ç†å¤šæ¨¡æ€ä¿¡æ¯
"""

# å¯¼å…¥æ ‡å‡†åº“
import base64  # ç”¨äºå›¾ç‰‡ç¼–ç 
import os  # ç”¨äºç³»ç»Ÿç›¸å…³æ“ä½œ
from typing import List, Tuple, Any  # ç±»å‹æç¤º

# å¯¼å…¥ç¬¬ä¸‰æ–¹åº“
import gradio as gr  # Gradioç•Œé¢åº“
from icecream import ic  # è°ƒè¯•æ‰“å°å·¥å…·
from PIL import Image  # å›¾ç‰‡å¤„ç†åº“
import PyPDF2  # PDFå¤„ç†åº“
import chardet  # å­—ç¬¦ç¼–ç æ£€æµ‹åº“
import mimetypes  # MIMEç±»å‹å¤„ç†åº“
from docx import Document  # Wordæ–‡æ¡£å¤„ç†åº“
from pydub import AudioSegment  # éŸ³é¢‘å¤„ç†åº“
import speech_recognition as sr  # è¯­éŸ³è¯†åˆ«åº“
from opencc import OpenCC  # ä¸­æ–‡ç¹ç®€è½¬æ¢åº“

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from question_answer.answer import get_answer  # è·å–ç­”æ¡ˆçš„å‡½æ•°
from question_answer.question_parser import parse_question  # è§£æé—®é¢˜ç±»å‹çš„å‡½æ•°
from question_answer.function_tool import process_image_describe_tool  # å›¾ç‰‡æè¿°å·¥å…·
from question_answer.purpose_type import userPurposeType  # ç”¨æˆ·é—®é¢˜ç±»å‹æšä¸¾

# å¯¼å…¥éŸ³é¢‘ç›¸å…³æ¨¡å—
from audio.audio_generate import audio_generate  # éŸ³é¢‘ç”Ÿæˆå‡½æ•°

# è®¾ç½®å¤´åƒè·¯å¾„
AVATAR = ("resource/user.png", "resource/bot.jpg")

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥è§£å†³å¤šçº¿ç¨‹é—®é¢˜
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


def convert_to_simplified(text: str) -> str:
    """
    å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
    
    Args:
        text (str): è¾“å…¥çš„ç¹ä½“ä¸­æ–‡æ–‡æœ¬
        
    Returns:
        str: è½¬æ¢åçš„ç®€ä½“ä¸­æ–‡æ–‡æœ¬
    """
    converter = OpenCC("t2s")  # åˆ›å»ºç¹ç®€è½¬æ¢å™¨å®ä¾‹ï¼Œä½¿ç”¨t2sæ¨¡å¼ï¼ˆç¹ä½“è½¬ç®€ä½“ï¼‰
    return converter.convert(text)  # æ‰§è¡Œç¹ç®€è½¬æ¢å¹¶è¿”å›ç»“æœ


def convert_audio_to_wav(audio_file_path: str) -> str:
    """
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºWAVæ ¼å¼
    
    Args:
        audio_file_path (str): åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: è½¬æ¢åçš„WAVæ–‡ä»¶è·¯å¾„
    """
    audio = AudioSegment.from_file(audio_file_path)  # ä½¿ç”¨pydubåŠ è½½éŸ³é¢‘æ–‡ä»¶
    wav_file_path = audio_file_path.rsplit(".", 1)[0] + ".wav"  # æ„é€ WAVæ–‡ä»¶è·¯å¾„ï¼Œæ›¿æ¢æ–‡ä»¶æ‰©å±•åä¸º.wav
    audio.export(wav_file_path, format="wav")  # å°†éŸ³é¢‘å¯¼å‡ºä¸ºWAVæ ¼å¼
    return wav_file_path  # è¿”å›è½¬æ¢åçš„WAVæ–‡ä»¶è·¯å¾„


def audio_to_text(audio_file_path: str) -> str:
    """
    å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡æœ¬
    
    Args:
        audio_file_path (str): éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: è¯†åˆ«å‡ºçš„æ–‡æœ¬å†…å®¹
    """
    # å¦‚æœä¸æ˜¯WAVæ ¼å¼ï¼Œå…ˆè½¬æ¢ä¸ºWAVæ ¼å¼
    if not audio_file_path.endswith(".wav"):
        audio_file_path = convert_audio_to_wav(audio_file_path)

    recognizer = sr.Recognizer()  # åˆ›å»ºè¯­éŸ³è¯†åˆ«å™¨å®ä¾‹
    with sr.AudioFile(audio_file_path) as source:  # æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
        audio_data = recognizer.record(source)  # ä»éŸ³é¢‘æ–‡ä»¶ä¸­è¯»å–éŸ³é¢‘æ•°æ®
        text = recognizer.recognize_whisper(audio_data, language="zh")  # ä½¿ç”¨Whisperæ¨¡å‹è¯†åˆ«ä¸­æ–‡è¯­éŸ³
        text_simplified = convert_to_simplified(text)  # å°†è¯†åˆ«ç»“æœè½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
    return text_simplified  # è¿”å›è¯†åˆ«å‡ºçš„ç®€ä½“ä¸­æ–‡æ–‡æœ¬


def pdf_to_str(pdf_file: str) -> str:
    """
    å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºæ–‡æœ¬å­—ç¬¦ä¸²
    
    Args:
        pdf_file (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹
    """
    reader = PyPDF2.PdfReader(pdf_file)  # åˆ›å»ºPDFè¯»å–å™¨å®ä¾‹
    text = ""  # åˆå§‹åŒ–ç©ºå­—ç¬¦ä¸²ç”¨äºå­˜å‚¨æå–çš„æ–‡æœ¬
    for page in reader.pages:  # éå†PDFä¸­çš„æ¯ä¸€é¡µ
        text += page.extract_text()  # æå–å½“å‰é¡µçš„æ–‡æœ¬å¹¶æ·»åŠ åˆ°ç»“æœä¸­
    return text  # è¿”å›æå–çš„æ‰€æœ‰æ–‡æœ¬


def docx_to_str(file_path: str) -> str:
    """
    å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºæ–‡æœ¬å­—ç¬¦ä¸²
    
    Args:
        file_path (str): Wordæ–‡æ¡£è·¯å¾„
        
    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹
    """
    doc = Document(file_path)  # æ‰“å¼€Wordæ–‡æ¡£
    text = [paragraph.text for paragraph in doc.paragraphs]  # æå–æ‰€æœ‰æ®µè½çš„æ–‡æœ¬
    return "\n".join(text)  # ç”¨æ¢è¡Œç¬¦è¿æ¥æ‰€æœ‰æ®µè½æ–‡æœ¬å¹¶è¿”å›


def text_file_to_str(text_file: str) -> str:
    """
    è¯»å–æ–‡æœ¬æ–‡ä»¶å†…å®¹
    
    Args:
        text_file (str): æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: æ–‡ä»¶å†…å®¹
    """
    with open(text_file, "rb") as file:  # ä»¥äºŒè¿›åˆ¶æ¨¡å¼æ‰“å¼€æ–‡ä»¶ç”¨äºæ£€æµ‹ç¼–ç 
        raw_data = file.read()  # è¯»å–æ–‡ä»¶çš„åŸå§‹æ•°æ®
        encoding = chardet.detect(raw_data)["encoding"]  # ä½¿ç”¨chardetåº“æ£€æµ‹æ–‡ä»¶ç¼–ç 
    with open(text_file, "r", encoding=encoding) as file:  # ä»¥æ£€æµ‹åˆ°çš„ç¼–ç é‡æ–°æ‰“å¼€æ–‡ä»¶
        return file.read()  # è¯»å–å¹¶è¿”å›æ–‡ä»¶å†…å®¹


def image_to_base64(image_path: str) -> str:
    """
    å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç 
    
    Args:
        image_path (str): å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
    """
    img = Image.open(image_path)  # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
    max_width = 800  # è®¾ç½®å›¾ç‰‡æœ€å¤§å®½åº¦ä¸º800åƒç´ 
    if img.width > max_width:  # å¦‚æœå›¾ç‰‡å®½åº¦è¶…è¿‡æœ€å¤§å®½åº¦
        ratio = max_width / img.width  # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        new_height = int(img.height * ratio)  # æ ¹æ®æ¯”ä¾‹è®¡ç®—æ–°çš„é«˜åº¦
        img = img.resize((max_width, new_height))  # è°ƒæ•´å›¾ç‰‡å°ºå¯¸
    
    temp_path = "temp_img.jpg"  # å®šä¹‰ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    img.save(temp_path)  # ä¿å­˜è°ƒæ•´å°ºå¯¸åçš„å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
    
    with open(temp_path, "rb") as f:  # ä»¥äºŒè¿›åˆ¶æ¨¡å¼æ‰“å¼€ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶
        encoded_string = base64.b64encode(f.read()).decode("utf-8")  # å°†å›¾ç‰‡ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
    
    os.remove(temp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    return encoded_string  # è¿”å›base64ç¼–ç çš„å›¾ç‰‡æ•°æ®


def grodio_view(chatbot: List, chat_input: dict) -> List:
    """
    å¤„ç†æ–‡æœ¬èŠå¤©ç•Œé¢çš„å‡½æ•°
    
    Args:
        chatbot (List): èŠå¤©å†å²è®°å½•
        chat_input (dict): ç”¨æˆ·è¾“å…¥å†…å®¹ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œæ–‡ä»¶
        
    Yields:
        List: æ›´æ–°åçš„èŠå¤©è®°å½•
    """
    # è·å–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
    user_message = chat_input["text"]
    # åˆå§‹åŒ–æœºå™¨äººå›å¤
    bot_response = "loading..."
    # å°†ç”¨æˆ·æ¶ˆæ¯å’Œåˆå§‹å›å¤æ·»åŠ åˆ°èŠå¤©è®°å½•
    chatbot.append([user_message, bot_response])
    yield chatbot  # è¿”å›æ›´æ–°åçš„èŠå¤©è®°å½•

    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    files = chat_input["files"]
    audios = []  # éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
    images = []  # å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
    pdfs = []  # PDFæ–‡ä»¶åˆ—è¡¨
    docxs = []  # Wordæ–‡æ¡£åˆ—è¡¨
    texts = []  # æ–‡æœ¬æ–‡ä»¶åˆ—è¡¨

    # åˆ†ç±»å¤„ç†ä¸åŒç±»å‹çš„æ–‡ä»¶
    for file in files:
        file_type, _ = mimetypes.guess_type(file)  # è·å–æ–‡ä»¶MIMEç±»å‹
        if file_type.startswith("audio/"):  # éŸ³é¢‘æ–‡ä»¶
            audios.append(file)
        elif file_type.startswith("image/"):  # å›¾ç‰‡æ–‡ä»¶
            images.append(file)
        elif file_type.startswith("application/pdf"):  # PDFæ–‡ä»¶
            pdfs.append(file)
        elif file_type.startswith(
                "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        ):  # Wordæ–‡æ¡£
            docxs.append(file)
        elif file_type.startswith("text/"):  # æ–‡æœ¬æ–‡ä»¶
            texts.append(file)
        else:  # ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹
            user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'è¯¥æ–‡ä»¶ä¸ºä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'"
            print(f"Unknown file type: {file_type}")

    # å¤„ç†å›¾ç‰‡æ–‡ä»¶
    if images:
        image_url = images
        image_base64 = [image_to_base64(image) for image in image_url]  # è½¬æ¢ä¸ºbase64
        for image in image_base64:
            # åœ¨èŠå¤©ç•Œé¢ä¸­æ˜¾ç¤ºå›¾ç‰‡
            chatbot[-1][0] += f"""
                <div>
                    <img src="data:image/png;base64,{image}" alt="Uploaded Image" style="max-width: 100%; height: auto; border-radius: 8px; margin: 8px 0;" />
                </div>
                """
            yield chatbot
    else:
        image_url = None

    # è§£æé—®é¢˜ç±»å‹
    question_type = parse_question(user_message, image_url)
    ic(question_type)  # è°ƒè¯•è¾“å‡ºé—®é¢˜ç±»å‹

    # å¤„ç†éŸ³é¢‘æ–‡ä»¶
    if audios:
        for i, audio in enumerate(audios):
            audio_message = audio_to_text(audio)  # éŸ³é¢‘è½¬æ–‡æœ¬
            if not audio_message:  # éŸ³é¢‘è¯†åˆ«å¤±è´¥
                user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·ç¨åå†è¯•'"
            elif "ä½œæ›²" in audio_message:  # è¯†åˆ«ä¸ºéŸ³ä¹
                user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'ä¸å¥½æ„æ€ï¼Œæˆ‘æ— æ³•ç†è§£éŸ³ä¹'"
            else:  # æ­£å¸¸è¯†åˆ«
                user_message += f"éŸ³é¢‘{i + 1}å†…å®¹ï¼š{audio_message}"

    # å¤„ç†PDFæ–‡ä»¶
    if pdfs:
        for i, pdf in enumerate(pdfs):
            user_message += f"PDF{i + 1}å†…å®¹ï¼š{pdf_to_str(pdf)}"  # æ·»åŠ PDFå†…å®¹

    # å¤„ç†Wordæ–‡æ¡£
    if docxs:
        for i, docx in enumerate(docxs):
            user_message += f"DOCX{i + 1}å†…å®¹ï¼š{docx_to_str(docx)}"  # æ·»åŠ Wordå†…å®¹

    # å¤„ç†æ–‡æœ¬æ–‡ä»¶
    if texts:
        for i, text in enumerate(texts):
            user_message += f"æ–‡æœ¬{i + 1}å†…å®¹ï¼š{text_file_to_str(text)}"  # æ·»åŠ æ–‡æœ¬å†…å®¹

    # å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œè®¾ç½®é»˜è®¤æ¶ˆæ¯
    if not user_message:
        user_message = "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'è¯·é—®æ‚¨æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„ï¼Œæˆ‘å°†å°½åŠ›ä¸ºæ‚¨æœåŠ¡'"
    
    # è·å–ç­”æ¡ˆ
    answer = get_answer(user_message, chatbot, question_type, image_url)
    bot_response = ""  # åˆå§‹åŒ–æœºå™¨äººå›å¤

    # å¤„ç†ä¸åŒç±»å‹çš„å›å¤
    if (
            answer[1] == userPurposeType.text
            or answer[1] == userPurposeType.RAG
            or answer[1] == userPurposeType.KnowledgeGraph
    ):
        # å¤„ç†æ–‡æœ¬å›å¤
        for chunk in answer[0]:
            bot_response += chunk.choices[0].delta.content or ""
            chatbot[-1][1] = bot_response
            yield chatbot

    if answer[1] == userPurposeType.ImageGeneration:
        # å¤„ç†å›¾ç‰‡ç”Ÿæˆå›å¤
        image_url = answer[0]
        describe = process_image_describe_tool(
            question_type=userPurposeType.ImageDescribe,
            question="æè¿°è¿™ä¸ªå›¾ç‰‡ï¼Œä¸è¦è¯†åˆ«'AIç”Ÿæˆ'",
            history="",
            image_url=[image_url],
        )
        combined_message = f"""
            **ç”Ÿæˆçš„å›¾ç‰‡:**
            ![Generated Image]({image_url})
            {describe[0]}
            """
        chatbot[-1][1] = combined_message
        yield chatbot

    if answer[1] == userPurposeType.ImageDescribe:
        # å¤„ç†å›¾ç‰‡æè¿°å›å¤
        for i in range(len(answer[0])):
            bot_response += answer[0][i:i + 1]
            chatbot[-1][1] = bot_response
            yield chatbot

    if answer[1] == userPurposeType.Video:
        # å¤„ç†è§†é¢‘å›å¤
        chatbot[-1][1] = answer[0] if answer[0] else "æŠ±æ­‰ï¼Œè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.PPT:
        # å¤„ç†PPTå›å¤
        chatbot[-1][1] = answer[0] if answer[0] else "æŠ±æ­‰ï¼ŒPPTç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.Docx:
        # å¤„ç†Wordæ–‡æ¡£å›å¤
        chatbot[-1][1] = answer[0] if answer[0] else "æŠ±æ­‰ï¼Œæ–‡æ¡£ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.Audio:
        # å¤„ç†éŸ³é¢‘å›å¤
        chatbot[-1][1] = answer[0] if answer[0] else "æŠ±æ­‰ï¼ŒéŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.InternetSearch:
        # å¤„ç†ç½‘ç»œæœç´¢å›å¤
        if not answer[3]:
            output_message = "ç”±äºç½‘ç»œé—®é¢˜ï¼Œè®¿é—®äº’è”ç½‘å¤±è´¥ï¼Œä¸‹é¢ç”±æˆ‘æ ¹æ®ç°æœ‰çŸ¥è¯†ç»™å‡ºå›ç­”ï¼š"
        else:
            links = "\n".join(f"[{title}]({link})" for link, title in answer[2].items())
            output_message = f"å‚è€ƒèµ„æ–™ï¼š{links}\n"
        for i in range(len(output_message)):
            bot_response = output_message[:i + 1]
            chatbot[-1][1] = bot_response
            yield chatbot
        for chunk in answer[0]:
            bot_response += chunk.choices[0].delta.content or ""
            chatbot[-1][1] = bot_response
            yield chatbot


def gradio_audio_view(chatbot: List, audio_input: str, lang_choice: str) -> List:
    """
    å¤„ç†è¯­éŸ³èŠå¤©ç•Œé¢çš„å‡½æ•°
    
    Args:
        chatbot (List): èŠå¤©å†å²è®°å½•
        audio_input (str): éŸ³é¢‘è¾“å…¥æ–‡ä»¶è·¯å¾„
        lang_choice (str): é€‰æ‹©çš„è¯­è¨€ç±»å‹
        
    Yields:
        List: æ›´æ–°åçš„èŠå¤©è®°å½•
    """
    # å¤„ç†ç”¨æˆ·éŸ³é¢‘è¾“å…¥
    user_message = (audio_input, "audio") if audio_input else ""
    bot_response = "loading..."  # åˆå§‹åŒ–æœºå™¨äººå›å¤
    chatbot.append([user_message, bot_response])  # æ·»åŠ åˆ°èŠå¤©è®°å½•
    yield chatbot

    # éŸ³é¢‘è½¬æ–‡æœ¬
    audio_message = audio_to_text(audio_input) if audio_input else "æ— éŸ³é¢‘"
    chatbot[-1][0] = audio_message  # æ›´æ–°ç”¨æˆ·æ¶ˆæ¯

    user_message = ""  # é‡ç½®ç”¨æˆ·æ¶ˆæ¯
    if audio_message == "æ— éŸ³é¢‘":  # æ²¡æœ‰éŸ³é¢‘è¾“å…¥
        user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'æ¬¢è¿ä¸æˆ‘å¯¹è¯ï¼Œæˆ‘å°†ç”¨è¯­éŸ³å›ç­”æ‚¨'"
    elif not audio_message:  # éŸ³é¢‘è¯†åˆ«å¤±è´¥
        user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·ç¨åå†è¯•'"
    elif "ä½œæ›² ä½œæ›²" in audio_message:  # è¯†åˆ«ä¸ºéŸ³ä¹
        user_message += "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'ä¸å¥½æ„æ€ï¼Œæˆ‘æ— æ³•ç†è§£éŸ³ä¹'"
    else:  # æ­£å¸¸è¯†åˆ«
        user_message += audio_message

    # å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œè®¾ç½®é»˜è®¤æ¶ˆæ¯
    if not user_message:
        user_message = "è¯·ä½ å°†ä¸‹é¢çš„å¥å­ä¿®é¥°åè¾“å‡ºï¼Œä¸è¦åŒ…å«é¢å¤–çš„æ–‡å­—ï¼Œå¥å­:'è¯·é—®æ‚¨æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„ï¼Œæˆ‘å°†å°½åŠ›ä¸ºæ‚¨æœåŠ¡'"

    # è§£æé—®é¢˜ç±»å‹
    question_type = parse_question(user_message)
    ic(question_type)  # è°ƒè¯•è¾“å‡ºé—®é¢˜ç±»å‹
    answer = get_answer(user_message, chatbot, question_type)  # è·å–ç­”æ¡ˆ
    bot_response = ""  # åˆå§‹åŒ–æœºå™¨äººå›å¤

    # å¤„ç†ä¸åŒç±»å‹çš„å›å¤
    if (
            answer[1] == userPurposeType.text
            or answer[1] == userPurposeType.RAG
            or answer[1] == userPurposeType.KnowledgeGraph
    ):
        # å¤„ç†æ–‡æœ¬å›å¤
        for chunk in answer[0]:
            bot_response += chunk.choices[0].delta.content or ""
        try:
            # æ ¹æ®é€‰æ‹©çš„æ–¹è¨€ç”Ÿæˆå¯¹åº”è¯­éŸ³
            model_map = {
                "æ™®é€šè¯ï¼ˆç”·ï¼‰": "zh-CN-YunxiNeural",
                "æ™®é€šè¯ï¼ˆå¥³ï¼‰": "zh-CN-XiaoxiaoNeural",
                "é™•è¥¿è¯": "zh-CN-shaanxi-XiaoniNeural",
                "ä¸œåŒ—è¯": "zh-CN-liaoning-XiaobeiNeural",
                "ç²¤è¯­ï¼ˆç”·ï¼‰": "zh-HK-WanLungNeural",
                "ç²¤è¯­ï¼ˆå¥³ï¼‰": "zh-HK-HiuMaanNeural"
            }
            # ç”ŸæˆéŸ³é¢‘å¹¶è¿”å›
            chatbot[-1][1] = (audio_generate(text=bot_response, model_name=model_map[lang_choice]), "audio")
        except Exception as e:
            print(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
            chatbot[-1][1] = bot_response
        yield chatbot

    if answer[1] == userPurposeType.ImageGeneration:
        # å¤„ç†å›¾ç‰‡ç”Ÿæˆå›å¤
        image_url = answer[0]
        describe = process_image_describe_tool(
            question_type=userPurposeType.ImageDescribe,
            question="æè¿°è¿™ä¸ªå›¾ç‰‡ï¼Œä¸è¦è¯†åˆ«'AIç”Ÿæˆ'",
            history=" ",
            image_url=[image_url],
        )
        combined_message = f"""
            **ç”Ÿæˆçš„å›¾ç‰‡:**
            ![Generated Image]({image_url})
            {describe[0]}
            """
        chatbot[-1][1] = combined_message
        yield chatbot

    if answer[1] == userPurposeType.Video:
        # å¤„ç†è§†é¢‘å›å¤
        if answer[0]:
            chatbot[-1][1] = answer[0]
        else:
            try:
                chatbot[-1][1] = (
                audio_generate(text="æŠ±æ­‰ï¼Œè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•", model_name="zh-CN-YunxiNeural"), "audio")
            except:
                chatbot[-1][1] = "æŠ±æ­‰ï¼Œè§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.PPT:
        # å¤„ç†PPTå›å¤
        if answer[0]:
            chatbot[-1][1] = answer[0]
        else:
            try:
                chatbot[-1][1] = (
                audio_generate(text="æŠ±æ­‰ï¼ŒPPTç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•", model_name="zh-CN-YunxiNeural"), "audio")
            except:
                chatbot[-1][1] = "æŠ±æ­‰ï¼ŒPPTç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.Docx:
        # å¤„ç†Wordæ–‡æ¡£å›å¤
        if answer[0]:
            chatbot[-1][1] = answer[0]
        else:
            try:
                chatbot[-1][1] = (
                audio_generate(text="æŠ±æ­‰ï¼Œæ–‡æ¡£ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•", model_name="zh-CN-YunxiNeural"), "audio")
            except:
                chatbot[-1][1] = "æŠ±æ­‰ï¼Œæ–‡æ¡£ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.Audio:
        # å¤„ç†éŸ³é¢‘å›å¤
        if answer[0]:
            chatbot[-1][1] = answer[0]
        else:
            try:
                chatbot[-1][1] = (
                audio_generate(text="æŠ±æ­‰ï¼ŒéŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•", model_name="zh-CN-YunxiNeural"), "audio")
            except:
                chatbot[-1][1] = "æŠ±æ­‰ï¼ŒéŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"
        yield chatbot

    if answer[1] == userPurposeType.InternetSearch:
        # å¤„ç†ç½‘ç»œæœç´¢å›å¤
        if not answer[3]:
            bot_response = "ç”±äºç½‘ç»œé—®é¢˜ï¼Œè®¿é—®äº’è”ç½‘å¤±è´¥ï¼Œä¸‹é¢ç”±æˆ‘æ ¹æ®ç°æœ‰çŸ¥è¯†ç»™å‡ºå›ç­”ï¼š"
        for chunk in answer[0]:
            bot_response += chunk.choices[0].delta.content or ""
        try:
            chatbot[-1][1] = (audio_generate(text=bot_response, model_name="zh-CN-YunxiNeural"), "audio")
        except:
            chatbot[-1][1] = bot_response
        yield chatbot


# ç¤ºä¾‹å¯¹è¯
examples = [
    {"text": "æ‚¨å¥½", "files": []},  # ç¤ºä¾‹1ï¼šç®€å•é—®å€™
    {"text": "è¿˜ç†¬å¤œå•Šï¼Ÿ", "files": []},  # ç¤ºä¾‹2ï¼šæ—¥å¸¸å¯¹è¯
    {"text": "ç”¨è¯­éŸ³é‡æ–°å›ç­”æˆ‘ä¸€æ¬¡", "files": []},  # ç¤ºä¾‹3ï¼šè¯­éŸ³å›å¤è¯·æ±‚
    {"text": "å¸®æˆ‘æœç´¢ä¸€ä¸‹å…»ç”ŸçŸ¥è¯†", "files": []},  # ç¤ºä¾‹4ï¼šç½‘ç»œæœç´¢è¯·æ±‚
    {"text": "ç§ƒå¤´æ€ä¹ˆåŠ", "files": []},  # ç¤ºä¾‹5ï¼šå¥åº·å’¨è¯¢
    {"text": "è¯·æ ¹æ®æˆ‘ç»™çš„å‚è€ƒèµ„æ–™ï¼Œç»™æˆ‘ä¸€ä¸ªåˆç†çš„é¥®é£Ÿå»ºè®®", "files": []},  # ç¤ºä¾‹6ï¼šåŸºäºèµ„æ–™çš„å»ºè®®
    {"text": "è¯·ç”Ÿæˆä¸€æ®µè€äººæ‰“å¤ªæçš„è§†é¢‘", "files": []},  # ç¤ºä¾‹7ï¼šå¤šåª’ä½“å†…å®¹ç”Ÿæˆ
]


# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="Doctor Strange ğŸ©º", theme=gr.themes.Soft()) as demo:
    # è‡ªå®šä¹‰CSSæ ·å¼
    gr.HTML("""
        <style>
            .gr-chatbot { 
                border-radius: 12px; 
                box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            }
            .gr-button-primary { 
                background-color: #4CAF50; 
                border-radius: 8px;
            }
            .gr-button { 
                border-radius: 8px;
                margin: 0 4px;
            }
            .gr-textbox, .gr-audio { 
                border-radius: 8px;
                border: 1px solid #ddd;
            }
            .tab-content {
                padding: 16px;
            }
        </style>
    """)

    # å…¨å±€èŠå¤©çŠ¶æ€ï¼ˆè·¨æ ‡ç­¾é¡µå…±äº«å¯¹è¯å†å²ï¼‰
    chatbot = gr.Chatbot(
        height=500,  # è®¾ç½®èŠå¤©çª—å£é«˜åº¦ä¸º500åƒç´ 
        avatar_images=AVATAR,  # è®¾ç½®ç”¨æˆ·å’Œæœºå™¨äººçš„å¤´åƒ
        show_copy_button=True,  # æ˜¾ç¤ºå¤åˆ¶æŒ‰é’®
        latex_delimiters=[  # æ”¯æŒçš„LaTeXæ•°å­¦å…¬å¼åˆ†éš”ç¬¦
            {"left": "\\(", "right": "\\)", "display": True},
            {"left": "\\[", "right": "\\]", "display": True},
            {"left": "$$", "right": "$$", "display": True},
            {"left": "$", "right": "$", "display": True},
        ],
        placeholder="å¼€å§‹å¯¹è¯å§...",  # èŠå¤©çª—å£å ä½ç¬¦æ–‡æœ¬
    )

    # æ ‡ç­¾é¡µå¸ƒå±€
    with gr.Tabs():
        # 1. æ–‡æœ¬å¯¹è¯æ ‡ç­¾é¡µ
        with gr.Tab("æ–‡æœ¬äº¤æµ", id="text-tab"):
            with gr.Row():
                chat_input = gr.MultimodalTextbox(
                    interactive=True,  # å¯ç”¨äº¤äº’
                    file_count="multiple",  # å…è®¸ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
                    placeholder="è¾“å…¥æ¶ˆæ¯æˆ–ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒå›¾ç‰‡ã€éŸ³é¢‘ã€PDFç­‰ï¼‰...",  # è¾“å…¥æ¡†å ä½ç¬¦
                    show_label=False,  # ä¸æ˜¾ç¤ºæ ‡ç­¾
                    scale=9  # å æ®9ä¸ªå•ä½å®½åº¦
                )
                submit_text = gr.Button("å‘é€", variant="primary", scale=1)  # å‘é€æŒ‰é’®

            # æ–‡æœ¬åŒºåŠŸèƒ½æŒ‰é’®
            with gr.Row():
                clear = gr.ClearButton([chatbot, chat_input], value="æ¸…é™¤è®°å½•")  # æ¸…é™¤è®°å½•æŒ‰é’®
                audio_from_text_btn = gr.Button("è¯­éŸ³å›å¤å½“å‰å†…å®¹")  # è¯­éŸ³å›å¤æŒ‰é’®

        # 2. è¯­éŸ³å¯¹è¯æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³å¯¹è¯", id="voice-tab"):
            with gr.Row():
                audio_input = gr.Audio(
                    sources=["microphone", "upload"],  # æ”¯æŒéº¦å…‹é£å½•éŸ³å’Œæ–‡ä»¶ä¸Šä¼ 
                    label="å½•éŸ³/ä¸Šä¼ éŸ³é¢‘",  # æ ‡ç­¾æ–‡æœ¬
                    type="filepath",  # è¿”å›æ–‡ä»¶è·¯å¾„
                    scale=8  # å æ®8ä¸ªå•ä½å®½åº¦
                )
                lang_choice = gr.Dropdown(
                    choices=["æ™®é€šè¯ï¼ˆç”·ï¼‰", "æ™®é€šè¯ï¼ˆå¥³ï¼‰", "é™•è¥¿è¯", "ä¸œåŒ—è¯", "ç²¤è¯­ï¼ˆç”·ï¼‰", "ç²¤è¯­ï¼ˆå¥³ï¼‰"],  # å¯é€‰é¡¹
                    label="è¯­éŸ³ç±»å‹",  # æ ‡ç­¾æ–‡æœ¬
                    value="æ™®é€šè¯ï¼ˆç”·ï¼‰",  # é»˜è®¤å€¼
                    scale=2  # å æ®2ä¸ªå•ä½å®½åº¦
                )

            with gr.Row():
                submit_audio = gr.Button("å‘é€è¯­éŸ³", variant="primary")  # å‘é€è¯­éŸ³æŒ‰é’®
                text_from_audio_btn = gr.Button("è½¬ä¸ºæ–‡å­—")  # è½¬ä¸ºæ–‡å­—æŒ‰é’®

        # 3. åŠŸèƒ½è¯´æ˜æ ‡ç­¾é¡µ
        with gr.Tab("åŠŸèƒ½æŒ‡å—", id="help-tab"):
            gr.Markdown("""
            ### åŠŸèƒ½è¯´æ˜
            - **æ–‡æœ¬äº¤æµ**ï¼šæ”¯æŒè¾“å…¥æ–‡å­—ã€ä¸Šä¼ æ–‡ä»¶ï¼ˆå›¾ç‰‡/éŸ³é¢‘/PDFç­‰ï¼‰ï¼Œå¯è·å–æ–‡æœ¬æˆ–å¤šåª’ä½“å›å¤
            - **è¯­éŸ³å¯¹è¯**ï¼šé€šè¿‡éº¦å…‹é£å½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘ï¼Œæ”¯æŒå¤šç§æ–¹è¨€è¾“å‡º
            - **æ–‡ä»¶å¤„ç†**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶è§£æPDFã€Wordã€å›¾ç‰‡ä¸­çš„å†…å®¹
            - **å¤šæ¨¡æ€ç”Ÿæˆ**ï¼šæ”¯æŒç”Ÿæˆå›¾ç‰‡ã€è§†é¢‘ã€PPTã€Wordæ–‡æ¡£

            ### ä½¿ç”¨ç¤ºä¾‹
            - ä¸Šä¼ ç—…å†å›¾ç‰‡ï¼Œæé—®"è¯·åˆ†æè¿™ä»½ç—…å†çš„å…³é”®ä¿¡æ¯"
            - å‘é€è¯­éŸ³"å¸®æˆ‘ç”Ÿæˆä¸€ä»½ç³–å°¿ç—…é¥®é£Ÿè®¡åˆ’"
            - è¾“å…¥æ–‡å­—"ç”¨çŸ¥è¯†åº“å†…å®¹ä»‹ç»é«˜è¡€å‹é¢„é˜²æªæ–½"
            """)
            # æŠ˜å å¼ç¤ºä¾‹
            with gr.Accordion("æŸ¥çœ‹å¯¹è¯ç¤ºä¾‹", open=False):
                gr.Examples(examples=examples, inputs=chat_input, examples_per_page=5)

    # äº‹ä»¶ç»‘å®š
    # æ–‡æœ¬æäº¤
    submit_text.click(
        fn=grodio_view,  # ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
        inputs=[chatbot, chat_input],  # è¾“å…¥å‚æ•°
        outputs=[chatbot]  # è¾“å‡ºå‚æ•°
    )
    #
    chat_input.submit(
        fn=grodio_view,  # å›è½¦æäº¤äº‹ä»¶å¤„ç†å‡½æ•°
        inputs=[chatbot, chat_input],  # è¾“å…¥å‚æ•°
        outputs=[chatbot]  # è¾“å‡ºå‚æ•°
    )

    # è¯­éŸ³æäº¤
    submit_audio.click(
        fn=gradio_audio_view,  # ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
        inputs=[chatbot, audio_input, lang_choice],  # è¾“å…¥å‚æ•°
        outputs=[chatbot]  # è¾“å‡ºå‚æ•°
    )


    # å¿«æ·åŠŸèƒ½ï¼šæ–‡æœ¬è½¬è¯­éŸ³å›å¤
    def text_to_audio_reply(chatbot):
        if not chatbot:
            return chatbot
        last_bot_msg = chatbot[-1][1]
        if isinstance(last_bot_msg, tuple) and last_bot_msg[1] == "audio":
            return chatbot  # å·²ä¸ºè¯­éŸ³
        try:
            audio_path = audio_generate(text=last_bot_msg, model_name="zh-CN-YunxiNeural")
            chatbot[-1][1] = (audio_path, "audio")
        except:
            pass
        return chatbot


    audio_from_text_btn.click(
        fn=text_to_audio_reply,  # ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
        inputs=[chatbot],  # è¾“å…¥å‚æ•°
        outputs=[chatbot]  # è¾“å‡ºå‚æ•°
    )


    # å¿«æ·åŠŸèƒ½ï¼šè¯­éŸ³è½¬æ–‡å­—
    def audio_to_text_shortcut(audio_input):
        if not audio_input:
            return ""
        return audio_to_text(audio_input)


    text_from_audio_btn.click(
        fn=audio_to_text_shortcut,  # ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
        inputs=[audio_input],  # è¾“å…¥å‚æ•°
        outputs=[chat_input]  # è¾“å‡ºå‚æ•°
    )


def start_gradio():
    """
    å¯åŠ¨Gradioåº”ç”¨
    """
    demo.launch(server_port=10086, share=True)  # å¯åŠ¨åº”ç”¨å¹¶åˆ†äº«


# ç¨‹åºå…¥å£ç‚¹
if __name__ == "__main__":
    start_gradio()  # è¿è¡Œåº”ç”¨